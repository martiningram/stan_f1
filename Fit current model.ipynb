{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = pd.read_csv('./ergast//races.csv')\n",
    "races['date'] = pd.to_datetime(races['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[races['raceId'] == 1063]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('./ergast//results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers = pd.read_csv('./ergast//drivers.csv')\n",
    "teams = pd.read_csv('./ergast//constructors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.merge(drivers, on='driverId')\n",
    "results = results.merge(teams, on='constructorId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results['raceId'] == 1072].sort_values('positionOrder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to 2020 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = races[races['date'].dt.year >= 2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_results = results[results['raceId'].isin(rel['raceId'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need: races, results, drivers, constructors, status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = rel_results['driverRef'].value_counts()\n",
    "enough = counts[counts > 2].index\n",
    "rel_results = rel_results[rel_results['driverRef'].isin(enough)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = pd.read_csv('./ergast//status.csv')\n",
    "rel_results = rel_results.merge(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_results = rel_results.merge(rel, on='raceId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix up 2015 Italian GP\n",
    "# Rosberg & Alonso technically finished because they covered more than 90% of the race, but\n",
    "# had serious car problems.\n",
    "rel_results.loc[(rel_results['raceId'] == 938) & (rel_results['status'].isin(['+3 Laps', '+6 Laps'])),\n",
    "                'status'] = 'DNF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team renamings\n",
    "sorted(rel_results['constructorRef'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamings = {\n",
    "    'racing_point': 'aston_martin',\n",
    "    'force_india': 'aston_martin',\n",
    "    'lotus_f1': 'alpine',\n",
    "    'marussia': 'haas',\n",
    "    'renault': 'alpine',\n",
    "    'sauber': 'alfa',\n",
    "    'toro_rosso': 'alphatauri'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_results['grouped_constructors'] = rel_results['constructorRef'].replace(renamings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_results['grouped_constructors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnf = ~rel_results['status'].str.contains('Finished|Lap').values\n",
    "\n",
    "dnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use just a single race to begin with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished = rel_results[~dnf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished = finished.sort_values(['raceId', 'positionOrder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_races = finished['raceId'].value_counts().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "driver_id = encoder.fit_transform(finished['driverRef'])\n",
    "\n",
    "team_encoder = LabelEncoder()\n",
    "\n",
    "team_id = team_encoder.fit_transform(finished['grouped_constructors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_encoder = LabelEncoder()\n",
    "\n",
    "race_ids = race_encoder.fit_transform(finished['raceId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sorted(race_ids) == race_ids).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_finished = pd.Series(race_ids).value_counts().sort_index().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_finished = race_ids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_encoder = LabelEncoder()\n",
    "\n",
    "years = year_encoder.fit_transform(finished['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_finished = rel_results[dnf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnf_race_ids = race_encoder.transform(not_finished['raceId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_ids_dnf = encoder.transform(not_finished['driverRef'])\n",
    "team_ids_dnf = team_encoder.transform(not_finished['grouped_constructors'])\n",
    "season_ids_dnf = year_encoder.transform(not_finished['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code = \"\"\"\n",
    "functions {\n",
    "    real compute_log_likelihood(vector cur_skills, int n_per_race) {\n",
    "    \n",
    "        real cur_lik = 0;\n",
    "\n",
    "        for (cur_position in 1:(n_per_race - 1)) {\n",
    "            vector[n_per_race - cur_position + 1] other_skills;\n",
    "\n",
    "            for (cur_other_position in cur_position:n_per_race) {\n",
    "                other_skills[cur_other_position - cur_position + 1] = cur_skills[cur_other_position];\n",
    "            }\n",
    "\n",
    "            real cur_numerator = cur_skills[cur_position];\n",
    "            real cur_denominator = log_sum_exp(other_skills);\n",
    "            cur_lik += cur_numerator - cur_denominator;\n",
    "        }\n",
    "        \n",
    "        return cur_lik;\n",
    "\n",
    "    }\n",
    "}\n",
    "data {\n",
    "    int n_drivers;\n",
    "    int n_races;\n",
    "    int n_teams;\n",
    "    int n_finished_by_race[n_races];\n",
    "    int n_finished_total;\n",
    "    int n_seasons;\n",
    "    \n",
    "    int driver_placings[n_finished_total];\n",
    "    int team_ids[n_finished_total];\n",
    "    int season_id[n_finished_total];\n",
    "    \n",
    "    int n_dnf;\n",
    "    \n",
    "    int team_ids_dnf[n_dnf];\n",
    "    int driver_ids_dnf[n_dnf];\n",
    "    int season_ids_dnf[n_dnf];\n",
    "    int race_ids_dnf[n_dnf];\n",
    "}\n",
    "parameters {\n",
    "    vector[n_drivers] driver_init_raw;\n",
    "    matrix[n_drivers, n_seasons - 1] driver_walk_raw;\n",
    "    \n",
    "    vector[n_drivers] driver_risk_init_raw;\n",
    "    real<lower=0> driver_risk_init_sd;\n",
    "        \n",
    "    vector[n_teams] team_risk_init_raw;\n",
    "    real<lower=0> team_risk_init_sd;\n",
    "\n",
    "    matrix[n_teams, n_seasons - 1] team_risk_walk_raw;\n",
    "    real<lower=0> team_risk_walk_sd;\n",
    "    \n",
    "    real dnf_intercept;\n",
    "    \n",
    "    real<lower=0> driver_init_sd;\n",
    "    real<lower=0> driver_season_sd;\n",
    "    \n",
    "    vector[n_teams] team_init_raw;\n",
    "    matrix[n_teams, n_seasons - 1] team_walk_raw;\n",
    "    \n",
    "    real<lower=0> team_init_sd;\n",
    "    real<lower=0> team_season_sd;\n",
    "}\n",
    "transformed parameters {\n",
    "    matrix[n_drivers, n_seasons] driver_skills;\n",
    "    matrix[n_teams, n_seasons] team_skills;\n",
    "    \n",
    "    vector[n_drivers] driver_risk;\n",
    "    matrix[n_teams, n_seasons] team_risk;\n",
    "    \n",
    "    for (cur_driver in 1:n_drivers) {\n",
    "        vector[n_seasons - 1] cur_offsets = cumulative_sum(driver_walk_raw[cur_driver])' * driver_season_sd;\n",
    "        driver_skills[cur_driver, 1] = driver_init_raw[cur_driver] * driver_init_sd;\n",
    "        driver_skills[cur_driver, 2:n_seasons] = driver_skills[cur_driver, 1] + cur_offsets';\n",
    "        \n",
    "        // DNF risk\n",
    "        driver_risk[cur_driver] = driver_risk_init_raw[cur_driver] * driver_risk_init_sd;\n",
    "    }\n",
    "\n",
    "    for (cur_team in 1:n_teams) {\n",
    "        vector[n_seasons - 1] cur_offsets = cumulative_sum(team_walk_raw[cur_team])' * team_season_sd;\n",
    "        team_skills[cur_team, 1] = team_init_raw[cur_team] * team_init_sd;\n",
    "        team_skills[cur_team, 2:n_seasons] = team_skills[cur_team, 1] + cur_offsets';\n",
    "        \n",
    "        // DNF risk\n",
    "        cur_offsets = cumulative_sum(team_risk_walk_raw[cur_team])' * team_risk_walk_sd;\n",
    "        team_risk[cur_team, 1] = team_risk_init_raw[cur_team] * team_risk_init_sd;\n",
    "        team_risk[cur_team, 2:n_seasons] = team_risk[cur_team, 1] + cur_offsets';\n",
    "    }\n",
    "\n",
    "}\n",
    "model {\n",
    "    int cur_start_index = 1;\n",
    "    \n",
    "    dnf_intercept ~ normal(0, 1);\n",
    "    \n",
    "    driver_risk_init_sd ~ normal(0, 1);\n",
    "    driver_risk_init_raw ~ std_normal();\n",
    "    \n",
    "    team_risk_init_raw ~ std_normal();\n",
    "    to_vector(team_risk_walk_raw) ~ std_normal();\n",
    "    team_risk_init_sd ~ normal(0, 1);\n",
    "    team_risk_walk_sd ~ normal(0, 1);\n",
    "    \n",
    "    driver_init_raw ~ std_normal();\n",
    "    to_vector(driver_walk_raw) ~ std_normal();\n",
    "    \n",
    "    team_init_raw ~ std_normal();\n",
    "    to_vector(team_walk_raw) ~ std_normal();\n",
    "    \n",
    "    team_init_sd ~ normal(0, 1);\n",
    "    driver_init_sd ~ normal(0, 1);\n",
    "    \n",
    "    team_season_sd ~ normal(0, 1);\n",
    "    driver_season_sd ~ normal(0, 1);\n",
    "    \n",
    "    // Conditional on finishing\n",
    "    for (cur_race in 1:n_races) {\n",
    "    \n",
    "        int cur_finished = n_finished_by_race[cur_race];\n",
    "    \n",
    "        vector[cur_finished] cur_skills;\n",
    "        \n",
    "        int cur_placements[cur_finished] = driver_placings[cur_start_index:cur_start_index+cur_finished-1];\n",
    "        int cur_teams[cur_finished] = team_ids[cur_start_index:cur_start_index+cur_finished-1];\n",
    "        int cur_seasons[cur_finished] = season_id[cur_start_index:cur_start_index+cur_finished-1];\n",
    "        \n",
    "        for (i in 1:cur_finished) {\n",
    "            cur_skills[i] = driver_skills[cur_placements[i], cur_seasons[i]] + \n",
    "            team_skills[cur_teams[i], cur_seasons[i]];\n",
    "            0 ~ bernoulli_logit(driver_risk[cur_placements[i]] + \n",
    "            team_risk[cur_teams[i], cur_seasons[i]] + dnf_intercept);\n",
    "        }\n",
    "        \n",
    "        target += compute_log_likelihood(cur_skills, cur_finished);\n",
    "        \n",
    "        cur_start_index += cur_finished;\n",
    "        \n",
    "    }\n",
    "    \n",
    "    // Conditional on not finishing\n",
    "    for (cur_dnf in 1:n_dnf) {\n",
    "        real cur_logit_prob_dnf = driver_risk[driver_ids_dnf[cur_dnf]] + \n",
    "        team_risk[team_ids_dnf[cur_dnf], season_ids_dnf[cur_dnf]] \n",
    "            + dnf_intercept;\n",
    "        1 ~ bernoulli_logit(cur_logit_prob_dnf);\n",
    "    }\n",
    "\n",
    "}\n",
    "generated quantities {\n",
    "\n",
    "    int cur_start_index = 1;\n",
    "\n",
    "    vector[n_races] log_likelihood;    \n",
    "    \n",
    "    // Conditional on finishing:\n",
    "    for (cur_race in 1:n_races) {\n",
    "    \n",
    "        int cur_finished = n_finished_by_race[cur_race];\n",
    "    \n",
    "        vector[cur_finished] cur_skills;\n",
    "        \n",
    "        int cur_placements[cur_finished] = driver_placings[cur_start_index:cur_start_index+cur_finished-1];\n",
    "        int cur_teams[cur_finished] = team_ids[cur_start_index:cur_start_index+cur_finished-1];\n",
    "        int cur_seasons[cur_finished] = season_id[cur_start_index:cur_start_index+cur_finished-1];\n",
    "        \n",
    "        log_likelihood[cur_race] = 0;\n",
    "        \n",
    "        for (i in 1:cur_finished) {\n",
    "            cur_skills[i] = driver_skills[cur_placements[i], cur_seasons[i]] + \n",
    "            team_skills[cur_teams[i], cur_seasons[i]];\n",
    "            \n",
    "            log_likelihood[cur_race] += bernoulli_logit_lpmf(\n",
    "                0 | driver_risk[cur_placements[i]] + \n",
    "                team_risk[cur_teams[i], cur_seasons[i]] + dnf_intercept);\n",
    "        }\n",
    "        \n",
    "        log_likelihood[cur_race] += compute_log_likelihood(cur_skills, cur_finished);\n",
    "        \n",
    "        cur_start_index += cur_finished;\n",
    "        \n",
    "    }\n",
    "    \n",
    "    // Conditional on not finishing:\n",
    "    for (cur_dnf in 1:n_dnf) {\n",
    "        real cur_logit_prob_dnf = driver_risk[driver_ids_dnf[cur_dnf]] + \n",
    "           team_risk[team_ids_dnf[cur_dnf], season_ids_dnf[cur_dnf]] + dnf_intercept;\n",
    "        log_likelihood[race_ids_dnf[cur_dnf]] += bernoulli_logit_lpmf(1 |cur_logit_prob_dnf);\n",
    "    }    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(model_code, file=open('./f1_model.stan', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmdstanpy import cmdstan_path, CmdStanModel\n",
    "import cmdstanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'n_drivers': len(encoder.classes_), \n",
    "        'n_finished_by_race': n_finished,\n",
    "        'n_finished_total': total_finished,\n",
    "        'n_races': n_races, \n",
    "        'driver_placings': driver_id + 1,\n",
    "        'season_id': years + 1,\n",
    "        'n_seasons': len(year_encoder.classes_),\n",
    "        'team_ids': team_id + 1, 'n_teams': len(team_encoder.classes_),\n",
    "        'n_dnf': not_finished.shape[0],\n",
    "        'driver_ids_dnf': driver_ids_dnf + 1,\n",
    "        'team_ids_dnf': team_ids_dnf + 1,\n",
    "        'season_ids_dnf': season_ids_dnf + 1,\n",
    "        'race_ids_dnf': dnf_race_ids + 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['season_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CmdStanModel(stan_file='./f1_model.stan')\n",
    "\n",
    "posterior = model.sample(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az \n",
    "\n",
    "fit = posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arviz_version = az.from_cmdstanpy(fit, log_likelihood='log_likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.rhat(arviz_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = posterior.stan_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit['driver_season_sd'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit['team_season_sd'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit['dnf_intercept'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_drivers = finished[finished['year'] == 2022]['driverRef'].unique()\n",
    "current_teams = finished[finished['year'] == 2022]['constructorRef'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "older_drivers = finished[finished['year'] == 2016]['driverRef'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit['driver_skills'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fit['driver_skills'].mean(axis=0), index=encoder.classes_,\n",
    "             columns=year_encoder.classes_).loc[current_drivers].round(3).sort_values(2022, ascending=False)[2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ml_tools.plotting import add_legend_on_right\n",
    "\n",
    "\n",
    "long_drivers = np.intersect1d(current_drivers, older_drivers)\n",
    "\n",
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "skills = pd.DataFrame(fit['driver_skills'].mean(axis=0), index=encoder.classes_,\n",
    "             columns=year_encoder.classes_).loc[current_drivers].round(3).sort_values(\n",
    "    2021, ascending=False).loc[long_drivers]\n",
    "\n",
    "skills.T.plot(legend=False, ax=ax, marker='o')\n",
    "\n",
    "f.set_size_inches(8, 4)\n",
    "\n",
    "add_legend_on_right(ax)\n",
    "\n",
    "#f.tight_layout()\n",
    "\n",
    "plt.title('Driver ratings since 2014')\n",
    "#plt.savefig('/home/martin/projects/martiningram.github.io/images/f1_post/driver_ratings.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_tools.plotting import add_legend_on_right\n",
    "\n",
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "pd.DataFrame(fit['team_skills'].mean(axis=0), index=team_encoder.classes_,\n",
    "             columns=year_encoder.classes_).round(3).loc[current_teams].sort_values(2021, ascending=False).T.plot(\n",
    "    ax=ax, legend=False, marker='o')\n",
    "\n",
    "ax.grid(alpha=0.5, linestyle='--')\n",
    "\n",
    "f.set_size_inches(10, 4)\n",
    "\n",
    "add_legend_on_right(ax)\n",
    "\n",
    "plt.title('Team ratings since 2014')\n",
    "#plt.savefig('/home/martin/projects/martiningram.github.io/images/f1_post/team_ratings.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_df = pd.DataFrame(\n",
    "    fit['driver_skills'].mean(axis=0), index=encoder.classes_, columns=year_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_drivers = finished[finished['year'] >= 2021]['driverRef'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_df.loc[current_drivers][2022].sort_values(ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_team_lookup = {encoder.transform([row.driverRef])[0]: team_encoder.transform([row.constructorRef])[0]\n",
    "                   for row in finished[finished['year'] == 2021].itertuples()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_df = pd.DataFrame(\n",
    "    fit['team_skills'].mean(axis=0), index=team_encoder.classes_, columns=year_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(driver_df.loc['max_verstappen'] + team_df.loc['red_bull']).plot(marker='o', label='Verstappen + Red Bull')\n",
    "(driver_df.loc['hamilton'] + team_df.loc['mercedes']).plot(marker='o', label='Hamilton + Mercedes')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "dnf_prob_mv = fit['driver_risk'][:, encoder.transform(['max_verstappen'])[0]] + fit['dnf_intercept'] + (\n",
    "fit['team_risk'][:, team_encoder.transform(['red_bull'])[0], -1])\n",
    "\n",
    "dnf_prob_lh = fit['driver_risk'][:, encoder.transform(['hamilton'])[0]] + fit['dnf_intercept'] + (\n",
    "fit['team_risk'][:, team_encoder.transform(['mercedes'])[0], -1])\n",
    "\n",
    "expit(dnf_prob_mv).mean(), expit(dnf_prob_lh).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit['driver_risk'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "team_risks = pd.DataFrame(expit((fit['team_risk'] + fit['dnf_intercept'].reshape(-1, 1, 1))).mean(axis=0), \n",
    "                          index=team_encoder.classes_, columns=year_encoder.classes_)\n",
    "\n",
    "team_risks.loc[current_teams].T.plot(ax=ax, legend=False, marker='o')\n",
    "\n",
    "ax.grid(alpha=0.5, linestyle='--')\n",
    "\n",
    "f.set_size_inches(12, 5)\n",
    "\n",
    "add_legend_on_right(ax)\n",
    "\n",
    "ax.set_ylabel('DNF probability')\n",
    "\n",
    "plt.title('DNF probability over time')\n",
    "#plt.savefig('/home/martin/projects/martiningram.github.io/images/f1_post/dnf_probs.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_risks = pd.Series((fit['driver_risk']).mean(axis=0), \n",
    "                          index=encoder.classes_)\n",
    "\n",
    "driver_risks.loc[current_drivers].sort_values(ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_df[2022].loc[current_teams].sort_values(ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "team_df.loc[current_teams].T.plot(ax=ax, marker='o')\n",
    "\n",
    "add_legend_on_right(ax)\n",
    "\n",
    "f.set_size_inches(10, 4)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at probability that Red Bull have the better car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merc_draws = fit['team_skills'][:, team_encoder.transform(['mercedes'])[0]]\n",
    "rb_draws = fit['team_skills'][:, team_encoder.transform(['red_bull'])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(team_df.columns, (rb_draws > merc_draws).mean(axis=-1), marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rb_draws > merc_draws).mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dnf = rel_results[dnf]['driverRef'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_skill = driver_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_show = set(n_dnf.index) & set(mean_skill.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as pxe\n",
    "import numpy as np\n",
    "\n",
    "pxe.scatter(x=n_dnf[to_show], y=mean_skill[to_show], hover_name=list(to_show))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "linregress(n_dnf[to_show], mean_skill[to_show])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit['driver_init_sd'].mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit['team_init_sd'].mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#az.from_pystan(fit, log_likelihood='log_likelihood').to_netcdf('/media/martin/big_extra_space/f1_fits/with_extra_teams.netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz_version = az.from_pystan(fit, log_likelihood=\"log_likelihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#az.to_netcdf(arviz_version, '/media/martin/big_extra_space/f1_fits/constant_driver_risk_2014.netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other_model = az.from_netcdf('/media/martin/big_extra_space/f1_fits/constant_driver_skills_2014.netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#az.compare({'dynamic_driver_skills': arviz_version, 'fixed_driver_skills': other_model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.loo(arviz_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_liks = pd.Series(fit['log_likelihood'].mean(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_liks = races.set_index('raceId')\n",
    "with_liks.loc[race_encoder.classes_, 'race_liks'] = race_liks.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_liks.shape, len(race_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_liks.dropna().sort_values('race_liks').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished[finished['raceId'] == 1063][['position', 'driverRef', 'status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can I simulate points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit['driver_skills'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_races = finished[finished['year'] == 2021]\n",
    "cur_combos = {row.driverRef: row.grouped_constructors for row in cur_races.itertuples()}\n",
    "\n",
    "combo_series = pd.Series(cur_combos)\n",
    "\n",
    "index_version = combo_series.copy()\n",
    "index_version.index = encoder.transform(index_version.index)\n",
    "index_version = index_version.apply(lambda x: team_encoder.transform([x])[0])\n",
    "#index_version = team_encoder.transform(index_version.values)\n",
    "\n",
    "index_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional on finishing\n",
    "cur_combo_skills = (fit['driver_skills'][index_version.index, -1, :] + \n",
    "                    fit['team_skills'][index_version.values, -1, :])\n",
    "\n",
    "# Probability of not finishing\n",
    "not_finish = (fit['driver_risk'][index_version.index, :] + \n",
    "              fit['team_risk'][index_version.values, -1, :] +\n",
    "              fit['dnf_intercept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cur_combo_skills, index=combo_series.index).loc['max_verstappen'].hist()\n",
    "pd.DataFrame(cur_combo_skills, index=combo_series.index).loc['hamilton'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_draws = pd.DataFrame(fit['driver_skills'][:, -1, :].T, columns=encoder.classes_)\n",
    "team_draws = pd.DataFrame(fit['team_skills'][:, -1, :].T, columns=team_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_probs = pd.DataFrame((np.exp(fit['driver_skills']) / (np.exp(fit['driver_skills']) + np.exp(0))).mean(axis=-1),\n",
    "             index=encoder.classes_, columns=year_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ml_tools.plotting import add_legend_on_right\n",
    "\n",
    "long_drivers = np.intersect1d(current_drivers, older_drivers)\n",
    "\n",
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "skills = driver_probs.loc[current_drivers].round(3).sort_values(\n",
    "    2021, ascending=False).loc[long_drivers]\n",
    "\n",
    "skills.T.plot(legend=False, ax=ax, marker='o')\n",
    "\n",
    "f.set_size_inches(8, 4)\n",
    "\n",
    "add_legend_on_right(ax)\n",
    "ax.grid(linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Win probability')\n",
    "\n",
    "#f.tight_layout()\n",
    "\n",
    "plt.title('Probability of beating average driver in a race')\n",
    "plt.savefig('/home/martin/projects/martiningram.github.io/images/f1_post/driver_probs.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.exp(driver_draws['max_verstappen']) / (np.exp(driver_draws['max_verstappen']) + np.exp(driver_draws['hamilton']))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(driver_draws['stroll'], driver_draws['vettel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "sns.distplot(driver_draws['hamilton'], ax=ax, label='Lewis Hamilton')\n",
    "sns.distplot(driver_draws['max_verstappen'], ax=ax, label='Max Verstappen')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('Skill (logit scale)')\n",
    "\n",
    "f.set_size_inches(7, 4)\n",
    "f.tight_layout()\n",
    "\n",
    "plt.savefig('./max_vs_lewis_kde.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "sns.distplot(team_draws['mercedes'], ax=ax, label='Mercedes')\n",
    "sns.distplot(team_draws['red_bull'], ax=ax, label='Red Bull')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('Skill (logit scale)')\n",
    "\n",
    "f.set_size_inches(7, 4)\n",
    "f.tight_layout()\n",
    "\n",
    "plt.savefig('./merc_rb_draws.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(np.percentile(driver_draws['max_verstappen'], [2.5, 50., 97.5]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(driver_draws['max_verstappen'] > driver_draws['hamilton'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array([25, 18, 15, 12, 10, 8, 6, 4, 2, 1])\n",
    "len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_results = list()\n",
    "\n",
    "# Simulate:\n",
    "for cur_draw in range(not_finish.shape[-1]):\n",
    "        \n",
    "    cur_points = np.zeros(cur_combo_skills.shape[0])\n",
    "    \n",
    "    cur_skills = cur_combo_skills[..., cur_draw].copy()\n",
    "    cur_prob_not_finish = expit(not_finish[..., cur_draw]).copy()\n",
    "    \n",
    "    finish = np.random.uniform(size=cur_prob_not_finish.shape[0]) > cur_prob_not_finish\n",
    "    \n",
    "    cur_skills[~finish] = -np.inf\n",
    "    \n",
    "    cur_result = pd.Series(cur_skills, index=combo_series.index)\n",
    "    \n",
    "    all_results.append(cur_result)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_results == -np.inf).mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gumbel: Maybe I can assume scale is 1? Check this.\n",
    "np.random.gumbel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array([25, 18, 15, 12, 10, 8, 6, 4, 2, 1])\n",
    "point_dict = {i+1: x for i, x in enumerate(points)}\n",
    "\n",
    "point_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eugh how do I actually generate a race outcome?\n",
    "# I guess I have to draw from Gumbels?\n",
    "\n",
    "all_points = list()\n",
    "all_orders = list()\n",
    "\n",
    "for i, cur_result in all_results.iterrows():\n",
    "    \n",
    "    cur_draw = pd.Series(np.random.gumbel(loc=cur_result, scale=1),\n",
    "                          index = cur_result.index)\n",
    "    \n",
    "    cur_order = cur_draw.sort_values(ascending=False)\n",
    "    cur_order = pd.Series(np.arange(cur_order.shape[0]) + 1, index=cur_order.index)\n",
    "    all_orders.append(cur_order)\n",
    "    \n",
    "    points = cur_order.apply(lambda x: point_dict.get(x, 0))\n",
    "    \n",
    "    points[cur_draw == -np.inf] = np.nan\n",
    "    \n",
    "    all_points.append(points)\n",
    "\n",
    "all_points = pd.DataFrame(all_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_orders)['max_verstappen'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points['max_verstappen'].hist()\n",
    "all_points['perez'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This doesn't make sense. Mazepin shouldn't be so high.\n",
    "# And the Verstappen thing doesn't make sense either. Perez shouldn't finish _that_ much more often. Hm.\n",
    "all_points.fillna(0).mean().sort_values(ascending=False).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_points['sainz'] + all_points['leclerc']).fillna(0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_points['norris'] + all_points['ricciardo']).fillna(0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15 * 17, 15 * 10.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_given_size(a, size):\n",
    "    return np.split(a, np.arange(size,len(a),size))\n",
    "\n",
    "\n",
    "point_splits = split_given_size(all_points.fillna(0).values, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_full = point_splits[:-1]\n",
    "\n",
    "assert(len(set([len(x) for x in only_full])) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_sims = [pd.Series(x.sum(axis=0), index=all_points.columns) for x in only_full]\n",
    "\n",
    "point_sims = pd.DataFrame(point_sims)\n",
    "\n",
    "point_sims['max_verstappen'].hist()\n",
    "point_sims['hamilton'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_sims['hamilton'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(point_sims['bottas'], [2.5, 50, 97.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_sims.apply(lambda x: np.percentile(x, [2.5, 50, 97.5]), axis=0).T.sort_values(1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(point_sims.idxmax(axis=1) == 'hamilton').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points['max_verstappen'].fillna(0).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((point_sims['hamilton'] - point_sims['max_verstappen']) > 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points['max_verstappen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / (1 - 0.2933)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points['hamilton'].fillna(0).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(expit(not_finish), index=combo_series.index).mean(axis=1).sort_values().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(expit(not_finish), index=combo_series.index).loc['max_verstappen'].hist()\n",
    "pd.DataFrame(expit(not_finish), index=combo_series.index).loc['hamilton'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_combo_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liks = pd.Series(fit['log_likelihood'].mean(axis=1), index=race_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liks.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[races['raceId'] == 1063]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[results['raceId'] == 1063].sort_values('positionOrder')[['position', 'driverRef']].reset_index(drop=True).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(4) / (np.exp(4) + np.exp(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gasly check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[races['name'].str.contains('Azerbaijan')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
